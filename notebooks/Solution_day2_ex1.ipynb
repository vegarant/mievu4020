{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data and create dataset objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/itf-fi-ml/home/vegarant/.local/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:174.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Dataset\n",
    "We can index Datasets manually like a list: `training_data[index]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img.shape:  torch.Size([1, 28, 28])\n",
      "img.dtype:  torch.float32\n",
      "img.device:  cpu\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "\n",
    "sample_idx = 105\n",
    "\n",
    "img, label = training_data[sample_idx]\n",
    "print('img.shape: ',  img.shape)\n",
    "print('img.dtype: ',  img.dtype)\n",
    "print('img.device: ', img.device) # Notice that the data is lying on the CPU. This is standard.\n",
    "\n",
    "plt.title(labels_map[label], fontsize=20)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataloaders\n",
    "The `Dataset` retrieves our dataset’s features and labels one sample at a time. When training a model, we typically want to pass samples in “minibatches” and reshuffle the data at every epoch to reduce model overfitting and use Python’s `multiprocessing` to speed up data retrieval.\n",
    "\n",
    "`DataLoader` is an iterable that abstracts this complexity for us in an easy API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "shuffle=True\n",
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=shuffle)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Iterate through the DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 2\n"
     ]
    }
   ],
   "source": [
    "# Display image and label.\n",
    "train_input, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Input batch shape: {train_input.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_input[0].squeeze()\n",
    "label = int(train_labels[0])\n",
    "\n",
    "plt.title(labels_map[label], fontsize=20)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model\n",
    "We define our neural network by subclassing `nn.Module`, and initialize the neural network layers in `__init__`. Every `nn.Module` subclass implements the operations on input data in the forward method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        # Create all the network layers (make sure the dimensions add up)\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding='same')\n",
    "        self.sig1 = nn.Sigmoid()\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, padding='valid')\n",
    "        self.sig2 = nn.Sigmoid()\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(in_features=5*5*16, out_features=120, bias=True)\n",
    "        self.sig3  = nn.Sigmoid()\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=84, bias=True)\n",
    "        self.sig4  = nn.Sigmoid()\n",
    "        self.fc3 = nn.Linear(in_features=84, out_features=10, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Specify how the layers should be connected\n",
    "        x = self.conv1(x)\n",
    "        x = self.sig1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.sig2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)     \n",
    "        x = self.sig3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sig4(x)\n",
    "        logits = self.fc3(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create network instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "  (sig1): Sigmoid()\n",
      "  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), padding=valid)\n",
      "  (sig2): Sigmoid()\n",
      "  (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (sig3): Sigmoid()\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (sig4): Sigmoid()\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = LeNet()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
       "  (sig1): Sigmoid()\n",
       "  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), padding=valid)\n",
       "  (sig2): Sigmoid()\n",
       "  (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (sig3): Sigmoid()\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (sig4): Sigmoid()\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a few hyperparameters\n",
    "device = torch.device('cuda')\n",
    "epochs = 5 # Number of iterations with stochastic gradient descent.\n",
    "learning_rate = 0.003\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() # Define the loss funciton\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) # Choose the optimizer \n",
    "model.to(device) # Move model parameters to the device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the train loop\n",
    "\n",
    "Inside the training loop, optimization happens in three steps:\n",
    " * Call `optimizer.zero_grad()` to reset the gradients of model parameters. Gradients by default add up; to prevent double-counting, we explicitly zero them at each iteration.\n",
    " * Backpropagate the prediction loss with a call to `loss.backward()`. PyTorch deposits the gradients of the loss w.r.t. each parameter.\n",
    " * Once we have our gradients, we call `optimizer.step()` to adjust the parameters by the gradients collected in the backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    batch = 0\n",
    "    for x, y in dataloader:\n",
    "        # Compute prediction and loss\n",
    "        batch = batch + 1\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad() # A common mistake is to forget to call this function.\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(x)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def validation_loop(dataloader, model, loss_fn, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    val_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            \n",
    "            val_loss += loss_fn(pred, y).item() # This is a float\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    val_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Validataion Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {val_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.339809  [ 6400/60000]\n",
      "loss: 2.306215  [12800/60000]\n",
      "loss: 2.300541  [19200/60000]\n",
      "loss: 2.301488  [25600/60000]\n",
      "loss: 2.304684  [32000/60000]\n",
      "loss: 2.305489  [38400/60000]\n",
      "loss: 2.303932  [44800/60000]\n",
      "loss: 2.302500  [51200/60000]\n",
      "loss: 2.301720  [57600/60000]\n",
      "Validataion Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.302619 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.302803  [ 6400/60000]\n",
      "loss: 2.299429  [12800/60000]\n",
      "loss: 2.302235  [19200/60000]\n",
      "loss: 2.301553  [25600/60000]\n",
      "loss: 2.306116  [32000/60000]\n",
      "loss: 2.305631  [38400/60000]\n",
      "loss: 2.300421  [44800/60000]\n",
      "loss: 2.299373  [51200/60000]\n",
      "loss: 2.304207  [57600/60000]\n",
      "Validataion Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.302794 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.295568  [ 6400/60000]\n",
      "loss: 2.307060  [12800/60000]\n",
      "loss: 2.304696  [19200/60000]\n",
      "loss: 2.302372  [25600/60000]\n",
      "loss: 2.303864  [32000/60000]\n",
      "loss: 2.301644  [38400/60000]\n",
      "loss: 2.303124  [44800/60000]\n",
      "loss: 2.301952  [51200/60000]\n",
      "loss: 2.304004  [57600/60000]\n",
      "Validataion Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.302803 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.301980  [ 6400/60000]\n",
      "loss: 2.305621  [12800/60000]\n",
      "loss: 2.298623  [19200/60000]\n",
      "loss: 2.301665  [25600/60000]\n",
      "loss: 2.303080  [32000/60000]\n",
      "loss: 2.300892  [38400/60000]\n",
      "loss: 2.303681  [44800/60000]\n",
      "loss: 2.308972  [51200/60000]\n",
      "loss: 2.303594  [57600/60000]\n",
      "Validataion Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.302748 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.301500  [ 6400/60000]\n",
      "loss: 2.302329  [12800/60000]\n",
      "loss: 2.303460  [19200/60000]\n",
      "loss: 2.304249  [25600/60000]\n",
      "loss: 2.302250  [32000/60000]\n",
      "loss: 2.305902  [38400/60000]\n",
      "loss: 2.301347  [44800/60000]\n",
      "loss: 2.305362  [51200/60000]\n",
      "loss: 2.300465  [57600/60000]\n",
      "Validataion Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.302662 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer, device)\n",
    "    validation_loop(test_dataloader, model, loss_fn, device)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
