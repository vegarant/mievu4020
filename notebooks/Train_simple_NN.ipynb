{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data and create dataset objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/itf-fi-ml/home/vegarant/.local/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:174.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Dataset\n",
    "We can index Datasets manually like a list: `training_data[index]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img.shape:  torch.Size([1, 28, 28])\n",
      "img.dtype:  torch.float32\n",
      "img.device:  cpu\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "\n",
    "sample_idx = 102\n",
    "\n",
    "img, label = training_data[sample_idx]\n",
    "print('img.shape: ', img.shape)\n",
    "print('img.dtype: ', img.dtype)\n",
    "print('img.device: ', img.device) # Notice that the data is lying on the CPU. This is standard.\n",
    "\n",
    "plt.title(labels_map[label], fontsize=20)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataloaders\n",
    "The `Dataset` retrieves our dataset’s features and labels one sample at a time. When training a model, we typically want to pass samples in “minibatches” and reshuffle the data at every epoch to reduce model overfitting and use Python’s `multiprocessing` to speed up data retrieval.\n",
    "\n",
    "`DataLoader` is an iterable that abstracts this complexity for us in an easy API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "shuffle=True\n",
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=shuffle)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Iterate through the DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 2\n"
     ]
    }
   ],
   "source": [
    "# Display image and label.\n",
    "train_input, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Input batch shape: {train_input.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_input[0].squeeze()\n",
    "label = int(train_labels[0])\n",
    "\n",
    "plt.title(labels_map[label], fontsize=20)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model\n",
    "We define our neural network by subclassing `nn.Module`, and initialize the neural network layers in `__init__`. Every `nn.Module` subclass implements the operations on input data in the forward method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        # Create all the network layers (make sure the dimensions add up)\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(in_features=28*28, out_features=512, bias=True)\n",
    "        self.r1  = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=512, bias=True)\n",
    "        self.r2  = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Specify how the layers should be connected\n",
    "        x = self.flatten(x) # Reshape the input from 28x28 matrices to vectors with length 28*28=784\n",
    "        x = self.fc1(x)     # Input must be flattend when using fully connecte layers\n",
    "        x = self.r1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.r2(x)\n",
    "        logits = self.fc3(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create network instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (r1): ReLU()\n",
      "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (r2): ReLU()\n",
      "  (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (r1): ReLU()\n",
       "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (r2): ReLU()\n",
       "  (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a few hyperparameters\n",
    "device = torch.device('cuda')\n",
    "epochs = 5 # Number of iterations with stochastic gradient descent.\n",
    "learning_rate = 0.003\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() # Define the loss funciton\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) # Choose the optimizer \n",
    "model.to(device) # Move model parameters to the device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the train loop\n",
    "\n",
    "Inside the training loop, optimization happens in three steps:\n",
    " * Call `optimizer.zero_grad()` to reset the gradients of model parameters. Gradients by default add up; to prevent double-counting, we explicitly zero them at each iteration.\n",
    " * Backpropagate the prediction loss with a call to `loss.backward()`. PyTorch deposits the gradients of the loss w.r.t. each parameter.\n",
    " * Once we have our gradients, we call `optimizer.step()` to adjust the parameters by the gradients collected in the backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad() # A common mistake is to forget to call this function.\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def validation_loop(dataloader, model, loss_fn, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    val_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            \n",
    "            val_loss += loss_fn(pred, y).item() # This is a float\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    val_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Validataion Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {val_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.298602  [    0/60000]\n",
      "loss: 2.269423  [ 6400/60000]\n",
      "loss: 2.206264  [12800/60000]\n",
      "loss: 2.127098  [19200/60000]\n",
      "loss: 2.084411  [25600/60000]\n",
      "loss: 1.989657  [32000/60000]\n",
      "loss: 1.887774  [38400/60000]\n",
      "loss: 1.805855  [44800/60000]\n",
      "loss: 1.687808  [51200/60000]\n",
      "loss: 1.538964  [57600/60000]\n",
      "Validataion Error: \n",
      " Accuracy: 59.6%, Avg loss: 1.509490 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.521326  [    0/60000]\n",
      "loss: 1.373688  [ 6400/60000]\n",
      "loss: 1.313775  [12800/60000]\n",
      "loss: 1.295273  [19200/60000]\n",
      "loss: 1.058606  [25600/60000]\n",
      "loss: 1.083523  [32000/60000]\n",
      "loss: 1.056002  [38400/60000]\n",
      "loss: 1.118214  [44800/60000]\n",
      "loss: 1.034540  [51200/60000]\n",
      "loss: 1.038817  [57600/60000]\n",
      "Validataion Error: \n",
      " Accuracy: 66.1%, Avg loss: 0.972886 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.830533  [    0/60000]\n",
      "loss: 0.889049  [ 6400/60000]\n",
      "loss: 0.884819  [12800/60000]\n",
      "loss: 0.978096  [19200/60000]\n",
      "loss: 1.000860  [25600/60000]\n",
      "loss: 0.795848  [32000/60000]\n",
      "loss: 0.831344  [38400/60000]\n",
      "loss: 0.861507  [44800/60000]\n",
      "loss: 0.838311  [51200/60000]\n",
      "loss: 0.840318  [57600/60000]\n",
      "Validataion Error: \n",
      " Accuracy: 69.8%, Avg loss: 0.815803 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.659123  [    0/60000]\n",
      "loss: 1.040967  [ 6400/60000]\n",
      "loss: 0.889767  [12800/60000]\n",
      "loss: 0.749100  [19200/60000]\n",
      "loss: 0.765105  [25600/60000]\n",
      "loss: 0.770465  [32000/60000]\n",
      "loss: 0.787724  [38400/60000]\n",
      "loss: 0.823533  [44800/60000]\n",
      "loss: 0.763941  [51200/60000]\n",
      "loss: 0.846706  [57600/60000]\n",
      "Validataion Error: \n",
      " Accuracy: 73.4%, Avg loss: 0.738001 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.972478  [    0/60000]\n",
      "loss: 0.554124  [ 6400/60000]\n",
      "loss: 0.767388  [12800/60000]\n",
      "loss: 0.630908  [19200/60000]\n",
      "loss: 0.559520  [25600/60000]\n",
      "loss: 0.689476  [32000/60000]\n",
      "loss: 0.774659  [38400/60000]\n",
      "loss: 0.660203  [44800/60000]\n",
      "loss: 0.655318  [51200/60000]\n",
      "loss: 0.807186  [57600/60000]\n",
      "Validataion Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.686731 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer, device)\n",
    "    validation_loop(test_dataloader, model, loss_fn, device)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
